# -*- coding: utf-8 -*-
"""zhekai_dg_learning_real

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1DdPOmN05EmDk5g89cklS87GkBRz0Kh5_
"""

# !gdown https://drive.google.com/uc?id=1bc1ChzmkYv9FDsZV_eapJFvrtsmT98Ly -O data.zip
#!gdown https://drive.google.com/uc?id=1pkzM2DmaJuDtJgLKIksRv7lGNI5U4zoZ -O data.zip
#!gdown https://drive.google.com/uc?id=16OcfSvJNRnkxNwM-ODy1RaME4VfJ6I_9 -O utils.zip
#!gdown https://drive.google.com/uc?id=1maXvXgpegcQMifNpP84blE1PARR2gvSO -O test.png

#!gdown https://drive.google.com/uc?id=13zsKk5w70eldr6YS5SXTleNO41NzanIG -O data_annotation_heightmap.zip
#!gdown https://drive.google.com/uc?id=1OwTbY4Fo61rcLZiIh-FJx2f7Y3CiqNv6 -O data_annotation_heightmap_0502.zip
#!gdown https://drive.google.com/uc?id=1vmRiNhAcFs5DHyphjMjxNsaeJSbrf9bS -O data_annotation_heightmap_0507.zip
!gdown https://drive.google.com/uc?id=1I4k-8LXoY9ALp2-bffaStEdfnIrum5yV -O data_annotation_heightmap_0511.zip

!rm -rf logs_val

!unzip -qq data_annotation_heightmap_0511.zip
!mkdir -p data/train
!mv raw_image data/train/input
!mv label data/train/label

pip install tqdm

"""# Rapid prototyping notebook
Use this to prototype quick ideas, then move to a script to scale up!

[Remember! we're always available for support on Slack](https://join.slack.com/t/pytorch-lightning/shared_invite/zt-f6bl2l0l-JYMK3tbAgAmGRrlNr00f1A)

# Setup
"""

# Commented out IPython magic to ensure Python compatibility.
import time
import os
import random
import matplotlib.pyplot as plt
import numpy as np
import cv2
import glob
import torch
from torch import nn
from torch.nn import functional as F
from torch.utils.data import Dataset, DataLoader, random_split
from torchvision import transforms
from torch.autograd import Variable
from PIL import Image

#from models import SteeringCommandsDQN, DenseActionSpaceDQN

# %matplotlib inline

class Normalize(object):
    """Normalize images
    """
    def __init__(self):
        self.image_mean = [0.485, 0.456, 0.406]
        self.image_std = [0.229, 0.224, 0.225]

    def __call__(self, sample):
        image, label = sample
        # Pre-process color image (scale and normalize)
        input_color_image = image.astype(float)/255
        for c in range(3):
            input_color_image[:,:,c] = (input_color_image[:,:,c] - self.image_mean[c])/self.image_std[c]
        return input_color_image, label

class ToTensor(object):
    """Convert ndarrays in sample to Tensors."""
    def __init__(self):
        self.transform = transforms.ToTensor()

    def __call__(self, sample):
        image, label = sample
        #image.shape = (image.shape[0], image.shape[1], image.shape[2], 1)
        label.shape = (label.shape[0], label.shape[1])
        image = torch.from_numpy(image.astype(np.float32)).permute(2,0,1)
        label = torch.from_numpy(label.astype(np.float32)).permute(0,1).long()
        return image, label

class BaseDataset(Dataset):
    def _convert_raw_label(self, label):
        """Convert raw label id to ready-to-train id"""
        label[label == 128] = 1
        label[label == 0] = 2
        label[label == 255] = 0
        return label


class MyDataset(BaseDataset):
    def __init__(self, data_dir='./data_annotation_heightmap', transform=None):
        """Custom dataset class

        Args
        :data_dir: Path to data directory
        :transform: Transform

        Attributes
        :data_dir:
        :transform:
        :image_filenames:
        :label_filenames:
        """
        self.data_dir = data_dir
        self.transform = transform

        self.image_filenames = glob.glob(os.path.join(data_dir, 'input', '*.png'))
        self.label_filenames = glob.glob(os.path.join(data_dir, 'label', '*.png'))

    def __len__(self):
        return len(self.image_filenames)

    def __getitem__(self, idx):
        image_filename = self.image_filenames[idx]
        label_filename = self.label_filenames[idx]

        image = np.array(Image.open(image_filename))
        label = np.array(Image.open(label_filename))
        if self.transform:
            image, label = self.transform((image, label))
            label = self._convert_raw_label(label)
        return image, label

class MyDataLoader():
    def __init__(self, batch_size, num_workers, data_dir='./data_annotation_heightmap'):
        super().__init__()
        self.data_dir = data_dir
        self.batch_size = batch_size
        self.num_workers = num_workers

    def setup(self):
        transform = transforms.Compose([
            Normalize(),
            ToTensor(),
        ])

        train_and_val = MyDataset(self.data_dir, transform)

        # Assign train/val datasets for use in dataloaders
        num_train = max(1, int(len(train_and_val) * 0.9))
        num_val = len(train_and_val) - num_train

        self.train, self.val = random_split(train_and_val, [num_train, num_val])

    def train_dataloader(self):
        return DataLoader(self.train, batch_size=self.batch_size, num_workers=self.num_workers)

    def val_dataloader(self):
        return DataLoader(self.val, batch_size=self.batch_size, num_workers=self.num_workers)

"""## Data Sanity check"""

data_dir = './data'
batch_size = 8
num_workers = 2
num_epochs = 50
device = 'cuda' if torch.cuda.is_available() else 'cpu'

"""## Build model"""

# Class distribution
transform = transforms.Compose([
            Normalize(),
            ToTensor(),
        ])
train_and_val = MyDataset(data_dir=data_dir + '/train', transform=transform)
dl = DataLoader(train_and_val, batch_size=batch_size, num_workers=0)

dataiter = iter(dl)
imgs, lbs = dataiter.next()
print("size", imgs.size(),lbs.size())

good_cnt = 0
bad_cnt = 0
for x, y in dl:
    good_cnt += (y.cpu().numpy() == 1).sum()
    bad_cnt += (y.cpu().numpy() == 2).sum()

total = good_cnt + bad_cnt
weights = [0, total / good_cnt, total / bad_cnt]
class_weights = torch.FloatTensor(weights)
if torch.cuda.is_available():
    class_weights = class_weights.cuda()
print('Class weights:', class_weights)

print(good_cnt,  bad_cnt)

# Construct customized ResNet

def conv3x3(in_planes, out_planes, stride=1):
    """3x3 convolution with padding"""
    return nn.Conv2d(in_planes, out_planes, kernel_size=3, stride=stride,
                     padding=1, bias=False)

class BasicBlock(nn.Module):
    expansion = 1

    def __init__(self, inplanes, planes, stride=1, downsample=None):
        super(BasicBlock, self).__init__()
        self.conv1 = conv3x3(inplanes, planes, stride)
        self.bn1 = nn.BatchNorm2d(planes)
        self.relu = nn.ReLU(inplace=True)
        self.conv2 = conv3x3(planes, planes)
        self.bn2 = nn.BatchNorm2d(planes)
        self.downsample = downsample
        self.stride = stride

    def forward(self, x):
        residual = x

        out = self.conv1(x)
        out = self.bn1(out)
        out = self.relu(out)

        out = self.conv2(out)
        out = self.bn2(out)

        if self.downsample is not None:
            residual = self.downsample(x)

        out += residual
        out = self.relu(out)

        return out

class myResNet(nn.Module):

    def __init__(self, pcpt_block, pcpt_layers, dg_block, dg_layers, dg_h, dg_w, dg_is_upsample=0):
        self.inplanes = 64
        #self.pcpt_is_upsample = pcpt_is_upsample
        super(myResNet, self).__init__()
        self.pcpt_conv1 = nn.Conv2d(3, 64, kernel_size=3, stride=1, padding=1,
                               bias=False)
        self.pcpt_bn1 = nn.BatchNorm2d(64)
        self.pcpt_relu = nn.ReLU(inplace=True)
        self.pcpt_maxpool = nn.MaxPool2d(kernel_size=2, stride=2, padding=0)
        self.pcpt_upsample = nn.Upsample(scale_factor=2, mode='bilinear')
        self.pcpt_layer1 = self._make_layer(pcpt_block, 128, pcpt_layers[0])
        self.pcpt_layer2 = self._make_layer(pcpt_block, 256, pcpt_layers[1])
        self.pcpt_layer3 = self._make_layer(pcpt_block, 512, pcpt_layers[2])

        self.inplanes = 512
        self.dg_is_upsample = dg_is_upsample
        self.dg_upsample = nn.Upsample(scale_factor=2, mode='bilinear')
        self.dg_layer1 = self._make_layer(dg_block, 256, dg_layers[0])
        self.dg_layer2 = self._make_layer(dg_block, 128, dg_layers[1])
        self.dg_layer3 = self._make_layer(dg_block, 64, dg_layers[2])
        self.dg_conv1 = nn.Conv2d(64, 1, kernel_size=3, stride=1, padding=1,
                               bias=False)
        self.dg_bn1 = nn.BatchNorm2d(1)
        self.dg_conv2 = nn.Conv2d(64, 3, kernel_size=3, stride=1, padding=1,
                               bias=False)
        self.dg_bn2 = nn.BatchNorm2d(3)
        self.dg_relu = nn.ReLU(inplace=True)

        self.dg_head = nn.Linear(dg_h*dg_w, 1)


        for m in self.modules():
            if isinstance(m, nn.Conv2d):
                nn.init.kaiming_normal_(m.weight, mode='fan_out', nonlinearity='relu')
            elif isinstance(m, nn.BatchNorm2d):
                nn.init.constant_(m.weight, 1)
                nn.init.constant_(m.bias, 0)


    def _make_layer(self, block, planes, blocks, stride=1):
        downsample = None
        if stride != 1 or self.inplanes != planes * block.expansion:
            downsample = nn.Sequential(
                nn.Conv2d(self.inplanes, planes * block.expansion,
                          kernel_size=1, stride=stride, bias=False),
                nn.BatchNorm2d(planes * block.expansion),
            )

        layers = []
        layers.append(block(self.inplanes, planes, stride, downsample))
        self.inplanes = planes * block.expansion
        for i in range(1, blocks):
            layers.append(block(self.inplanes, planes))

        return nn.Sequential(*layers)

    def forward(self, x):
        x = self.pcpt_conv1(x)
        x = self.pcpt_bn1(x)
        x = self.pcpt_relu(x)
        x = self.pcpt_maxpool(x)

        x = self.pcpt_layer1(x)
        x = self.pcpt_maxpool(x)
        x = self.pcpt_layer2(x)
        x = self.pcpt_layer3(x)

        x = self.dg_layer1(x)
        x = self.dg_layer2(x)
        x = self.dg_upsample(x)
        x = self.dg_layer3(x)
        x = self.dg_upsample(x)

        x = self.dg_conv2(x)
        x = self.dg_bn2(x)
        x = self.dg_relu(x)

        return x

from torchsummary import summary

model = myResNet(BasicBlock,[1,1,1],BasicBlock,[1,1,1],200,200).cuda()
#print(model)
summary(model,(3,200,200))

"""## Train
We would define a LightningModule instance to ultilize pytorch lightning training pipeline.
"""

from tqdm import tqdm
from torch.utils.tensorboard import SummaryWriter
import math

data_dir = './data'
batch_size = 32
num_workers = 12
num_epochs = 100
device = 'cuda' if torch.cuda.is_available() else 'cpu'

writer_val = SummaryWriter('./logs_val')
writer_train = SummaryWriter('./logs_train')

my_loader = MyDataLoader(batch_size, num_workers, data_dir=data_dir + '/train')
my_loader.setup()
train_loader = my_loader.train_dataloader()
val_loader = my_loader.val_dataloader()

optimizer = torch.optim.SGD(model.parameters(), lr=1e-4, momentum=0.9, weight_decay=2e-5)
loss_func = torch.nn.CrossEntropyLoss(ignore_index=0, weight=class_weights)  # the target label is NOT an one-hotted

acc = []

count_first_loss = 0
for epoch in range(num_epochs):
  train_loss_hist = []
  val_loss_hist = []
  model.cuda().train()
  with torch.enable_grad():
    for step, (batch_data, batch_label) in enumerate(train_loader):
      batch_data = batch_data.cuda()
      batch_label = batch_label.cuda()
      output = model(batch_data)              # get output for every net
      train_loss = loss_func(output, batch_label)  # compute loss for every net
      optimizer.zero_grad()                # clear gradients for next train
      train_loss.backward()                # backpropagation, compute gradients
      optimizer.step()                     # apply gradients
      train_loss_print = train_loss.data.item()     # loss recoder
      #writer.add_scalar('Train/Loss', train_loss_print, step) 
      print("epoch: ", epoch, 'step: ', step, 'train_loss: ', train_loss_print)
      train_loss_hist.append(train_loss_print)
    train_loss_mean = np.mean(np.array(train_loss_hist))
    writer_train.add_scalar('train loss', train_loss_mean, epoch)


  model.eval()
  with torch.no_grad():
    loop = tqdm(enumerate(val_loader), total=len(val_loader), leave=False)
    for step, (batch_val_data, batch_val_label) in loop:
      batch_val_data = batch_val_data.cuda()
      batch_val_label = batch_val_label.cuda()
      val_output = model(batch_val_data)
      val_loss = loss_func(val_output, batch_val_label)
      val_loss_print = val_loss.data.item()
      print("epoch: ", epoch, 'step: ', step, 'val_loss: ', val_loss_print)
#      if count_first_loss < 1:
#        val_loss_hist.append(val_loss_print)
#        acc_e = math.exp(-val_loss_print)
#        acc.append(acc_e)
#        count_first_loss += 1
#      acc_e = math.exp(-val_loss_print)
#      acc.append(acc_e)
#      writer.add_scalar('accuracy', acc_e, epoch)
      val_loss_hist.append(val_loss_print)
      loop.set_description(f"Epoch [{epoch}/{num_epochs}]")
      loop.set_postfix(train_loss = train_loss_mean, val_loss = val_loss_print)
    val_loss_mean = np.mean(np.array(val_loss_hist))
    writer_val.add_scalar('val loss', val_loss_mean, epoch)

  torch.save(model.cpu().state_dict(), os.path.join(data_dir, 'weights-%06d.pth' % (epoch)))

dataiter = iter(val_loader)
imgs, lbs = dataiter.next()
print("size", len(imgs))

model.load_state_dict(torch.load('./data/weights-000040.pth'))

from torch.utils.tensorboard import SummaryWriter
import math

writer = SummaryWriter('./logs')
acc = [0.47104570269584656,0.33758652210235596,0.2613864541053772,0.20150090754032135,0.16262106597423553,0.1335211843252182,0.10855705291032791,0.09055507928133011,0.07865428179502487,\
       0.06936140358448029,0.06209225207567215,0.05627521499991417,0.05176911875605583,0.04797092080116272,0.04465200752019882,0.04187583550810814,0.039066534489393234,0.03687410429120064,\
       0.03475066274404526,0.03281043842434883,0.03113875538110733,0.029673242941498756,0.02827715128660202,0.027006715536117554,0.02570517547428608,0.02455184794962406,0.023484786972403526,\
       0.022467251867055893,0.021537354215979576,0.020619962364435196]
print(len(acc))
for epoch in range(30):
  acc_e = math.exp(-acc[epoch])
  writer.add_scalar('accuracy', acc_e, epoch)
writer.close()

print((loss_hist))

!kill 107

# Commented out IPython magic to ensure Python compatibility.
# Start tensorboard.
# %reload_ext tensorboard
# %tensorboard --logdir ./logs_val

# Commented out IPython magic to ensure Python compatibility.
# Start tensorboard.
# %reload_ext tensorboard
# %tensorboard --logdir ./logs_train